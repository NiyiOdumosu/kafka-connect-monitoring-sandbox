global:
  # How frequently to scrape targets by default.
  # Default 15s
  scrape_interval:     60s
  # How frequently to evaluate rules.
  # Default 15s
  evaluation_interval: 15s
  # How long until a scrape request times out.
  # Default to 10s.
  # Required because cp-demo is using cpu throttling, so let's leave enough time to fetch the metrics in particular for the first time as it needs to compile all rexps
  scrape_timeout: 30s

rule_files:
  - 'alert.rules'

alerting:
  alertmanagers:
  - scheme: http
    static_configs:
    - targets:
      - "alertmanager:9093"

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
    - targets: ['localhost:9090']

  - job_name: Confluent Cloud
    scrape_interval: 1m
    scrape_timeout: 1m
    honor_timestamps: true
    static_configs:
      - targets:
          - api.telemetry.confluent.cloud
    scheme: https
    basic_auth:
      username: ${CCLOUD_EXPORTER_API_KEY}
      password: ${CCLOUD_EXPORTER_API_SECRET}
    metrics_path: /v2/metrics/cloud/export
    params:
      "resource.kafka.id":
        - ${CCLOUD_CLUSTER}
      "resource.connector.id":

  - job_name: 'kafka-connect'
    scrape_interval: 60s
    scrape_timeout: 30s
    honor_timestamps: true
    static_configs:
      - targets: [ 'connect1:5083' ]
        labels:
          env: "dev"
          kafka_connect_cluster_id: "cluster1"
    relabel_configs:
      - source_labels: [ __address__ ]
        target_label: hostname
        regex: '([^:]+)(:[0-9]+)?'
        replacement: '${1}'


  - job_name: 'kafka-lag-exporter'
    static_configs:
      - targets:
          - 'kafka-lag-exporter:9999'

